{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2bf6dc",
   "metadata": {},
   "source": [
    "# Task 1: Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5cdac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "housing = fetch_california_housing()\n",
    "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "y = housing.target\n",
    "\n",
    "# Using 'AveRooms' as the feature\n",
    "X_rooms = X[['AveRooms']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rooms, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X_test, y_test, color='blue', label='Actual')\n",
    "plt.plot(X_test, model.predict(X_test), color='red', linewidth=2, label='Regression Line')\n",
    "plt.xlabel('Average Rooms')\n",
    "plt.ylabel('House Value')\n",
    "plt.title('Simple Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bcf179",
   "metadata": {},
   "source": [
    "# Task 2: Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44388a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Use multiple features\n",
    "features = ['MedInc', 'HouseAge', 'AveRooms', 'AveOccup']\n",
    "X_multi = X[features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_multi, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_multi = LinearRegression()\n",
    "model_multi.fit(X_train, y_train)\n",
    "y_pred = model_multi.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"Coefficients:\", model_multi.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e85e66",
   "metadata": {},
   "source": [
    "# Task 3: Feature Scaling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_multi)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train, y_train)\n",
    "y_pred_scaled = model_scaled.predict(X_test)\n",
    "\n",
    "r2_scaled = r2_score(y_test, y_pred_scaled)\n",
    "rmse_scaled = np.sqrt(mean_squared_error(y_test, y_pred_scaled))\n",
    "\n",
    "print(\"R-squared (scaled):\", r2_scaled)\n",
    "print(\"RMSE (scaled):\", rmse_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72403b3b",
   "metadata": {},
   "source": [
    "# Task 4: Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d7d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "\n",
    "corr_matrix = X[features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Discuss multicollinearity\n",
    "print(\"Features with high correlation may indicate multicollinearity which can distort model coefficients.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a4feed",
   "metadata": {},
   "source": [
    "# Task 5: Binary Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcea029",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\n",
    "\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\n",
    "\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ddcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_probs = clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "plt.plot(fpr, tpr, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_probs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f6cee7",
   "metadata": {},
   "source": [
    "# Task 6: Threshold Tuning and Probability Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c66644",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for threshold in [0.3, 0.5, 0.7]:\n",
    "    y_thresh = (y_probs >= threshold).astype(int)\n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(\"Confusion Matrix:\n",
    "\", confusion_matrix(y_test, y_thresh))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_thresh))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c234300",
   "metadata": {},
   "source": [
    "# Task 7: Multiclass Classification (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb0a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf_multi = LogisticRegression(multi_class='ovr', max_iter=10000)\n",
    "clf_multi.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_multi.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\n",
    "\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ead35",
   "metadata": {},
   "source": [
    "# Part III: General Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60fb5c",
   "metadata": {},
   "source": [
    "\n",
    "**1. What are the assumptions of linear regression?**  \n",
    "Linear regression assumes linearity between features and target, independence of errors, homoscedasticity (constant variance of errors), and no multicollinearity among predictors.\n",
    "\n",
    "**2. When should you use logistic regression instead of linear regression?**  \n",
    "Use logistic regression when the target variable is categorical (especially binary), such as yes/no or 0/1.\n",
    "\n",
    "**3. What is the interpretation of coefficients in logistic regression?**  \n",
    "The coefficients represent the change in the log odds of the target variable for a one-unit increase in the predictor.\n",
    "\n",
    "**4. What is the difference between sigmoid and softmax functions?**  \n",
    "Sigmoid maps values to a probability between 0 and 1 for binary classification. Softmax generalizes this to multi-class classification, ensuring outputs sum to 1.\n",
    "\n",
    "**5. Why is R-squared not suitable for evaluating logistic regression models?**  \n",
    "R-squared measures variance explained, suitable for regression, not classification. Logistic regression uses measures like AUC, accuracy, or log loss instead.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}